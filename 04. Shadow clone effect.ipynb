{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "import tarfile\n",
    "import tempfile\n",
    "from six.moves import urllib\n",
    "\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from model_deeplab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !brew install ffmpeg\n",
    "# !pip3 install ffmpeg ffprobe scikit-video pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~/magic-effect/Uptown Funk Dance  Freestyle Dancer  Awesome Skills.mp4'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytube import YouTube\n",
    "# url = \"https://www.youtube.com/watch?v=G9ZM43ZpoCE\" # Roger\n",
    "# url = \"https://www.youtube.com/watch?v=qAJLHBB5Js0\" # Djokovic\n",
    "# url = \"https://www.youtube.com/watch?v=JA7G7AV-LT8\" # Jordan\n",
    "# url = \"https://www.youtube.com/watch?v=qWtukUCglFs\" # Aaron\n",
    "url = \"https://www.youtube.com/watch?v=FVKNoN4OhQY\" # solo\n",
    "yt = YouTube(url)\n",
    "yt.streams.first().download('~/magic-effect/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading model, this might take a while...\n",
      "download completed! loading DeepLab model...\n",
      "model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'mobilenetv2_coco_voctrainaug'  # @param ['mobilenetv2_coco_voctrainaug', 'mobilenetv2_coco_voctrainval', 'xception_coco_voctrainaug', 'xception_coco_voctrainval']\n",
    "\n",
    "_DOWNLOAD_URL_PREFIX = 'http://download.tensorflow.org/models/'\n",
    "_MODEL_URLS = {\n",
    "    'mobilenetv2_coco_voctrainaug':\n",
    "        'deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz',\n",
    "    'mobilenetv2_coco_voctrainval':\n",
    "        'deeplabv3_mnv2_pascal_trainval_2018_01_29.tar.gz',\n",
    "    'xception_coco_voctrainaug':\n",
    "        'deeplabv3_pascal_train_aug_2018_01_04.tar.gz',\n",
    "    'xception_coco_voctrainval':\n",
    "        'deeplabv3_pascal_trainval_2018_01_04.tar.gz',\n",
    "}\n",
    "_TARBALL_NAME = 'deeplab_model.tar.gz'\n",
    "\n",
    "model_dir = 'model/'#tempfile.mkdtemp()\n",
    "tf.gfile.MakeDirs(model_dir)\n",
    "\n",
    "download_path = os.path.join(model_dir, _TARBALL_NAME)\n",
    "print('downloading model, this might take a while...')\n",
    "urllib.request.urlretrieve(_DOWNLOAD_URL_PREFIX + _MODEL_URLS[MODEL_NAME],\n",
    "                   download_path)\n",
    "print('download completed! loading DeepLab model...')\n",
    "\n",
    "MODEL = DeepLabModel(download_path)\n",
    "print('model loaded successfully!')\n",
    "\n",
    "#@title Run on sample images {display-mode: \"form\"}\n",
    "\n",
    "SAMPLE_IMAGE = 'image1'  # @param ['image1', 'image2', 'image3']\n",
    "IMAGE_URL = ''  #@param {type:\"string\"}\n",
    "\n",
    "_SAMPLE_URL = ('https://github.com/tensorflow/models/blob/master/research/'\n",
    "               'deeplab/g3doc/img/%s.jpg?raw=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_visualization(f, verbose=False):\n",
    "    \"\"\"Inferences DeepLab model and visualizes result.\"\"\"\n",
    "    try:\n",
    "        if isinstance(f, str):\n",
    "            original_im = Image.open(f)\n",
    "        elif isinstance(f, np.ndarray):\n",
    "            original_im = Image.fromarray(f)\n",
    "    except:\n",
    "        print(\"Unexpected error: invalid input\")\n",
    "        raise\n",
    "    \n",
    "#     print('running deeplab on image %s...' % f)\n",
    "    resized_im, seg_map = MODEL.run(original_im)\n",
    "    if verbose:\n",
    "        vis_segmentation(resized_im, seg_map)\n",
    "    return resized_im, seg_map\n",
    "\n",
    "def find_cntr(cv2_img, n_max=5, th=1000):\n",
    "    '''input: cv2_img = cv2.imread(img_path)'''\n",
    "    '''output: mask '''\n",
    "    b,g,r = cv2.split(cv2_img)  \n",
    "    img = cv2.merge([r,g,b])\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _,th2 = cv2.threshold(gray,10,1,cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(th2,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    areas = [-cv2.contourArea(contour) for contour in contours]\n",
    "    num = max(n_max, np.sum(np.array(areas) < (-1)*th))\n",
    "    return [contours[top] for top in np.argsort(areas)[:num]]\n",
    "\n",
    "def get_stroke(person_mask, width=10):\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_RECT,(width,width))\n",
    "    dilate = cv2.dilate(person_mask, element)\n",
    "    result = cv2.absdiff(dilate, person_mask)\n",
    "    retval, result = cv2.threshold(result, 0, 255, cv2.THRESH_BINARY)\n",
    "    result_mask = np.stack((result/255.0,\n",
    "                               result/255.0,\n",
    "                               result/255.0), axis=2).astype(np.uint8)\n",
    "    result_mask = cv2.medianBlur(result_mask, 1)\n",
    "    return result_mask\n",
    "\n",
    "def run_offset_effect(f, shift_x, shift_y):\n",
    "    rgb, mask = run_visualization(f)\n",
    "    rgb = np.array(rgb)\n",
    "    fore = np.array(mask == 15, np.uint8) * 255\n",
    "    fore = np.stack((fore, fore, fore),axis=2).astype(np.uint8)\n",
    "\n",
    "    # find contours on person semantic mask\n",
    "    k = find_cntr(fore)\n",
    "\n",
    "    # select at most five contours\n",
    "    num = min(len(k), 5)\n",
    "    colors = [(252,141,98),(102,194,165), (141,160,203),(231,138,195),(166,216,84)]\n",
    "\n",
    "    # combine all contours with different colors\n",
    "    s = np.zeros(rgb.shape, np.uint8)\n",
    "    for i in range(num):\n",
    "        canvas = np.zeros(rgb.shape[0:2], np.uint8)\n",
    "        one_mask = cv2.drawContours(canvas, k, i, (255,255,255),-1)\n",
    "        color_fore = np.stack((one_mask / 255 * colors[i][0],\n",
    "                               one_mask / 255 * colors[i][1],\n",
    "                               one_mask / 255 * colors[i][2]), axis=2).astype(np.uint8)\n",
    "        color_fore = get_shifted_image(color_fore, shift_x, shift_y).astype(np.uint8)\n",
    "        s += color_fore\n",
    "    s = s*(1-(fore>0))\n",
    "\n",
    "    # combine with original images\n",
    "    rgb_new = rgb*(1-(s>0)) + s\n",
    "    return rgb, rgb_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check step-by-step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4219, 720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "import skvideo.io\n",
    "from skimage.transform import resize\n",
    "\n",
    "filename = 'video_SuperMario.mp4'\n",
    "cap = skvideo.io.vread(filename)\n",
    "print(cap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filename == 'video_Roger.mp4':\n",
    "    video = cap[0:500:3]\n",
    "elif filename == 'video_Kobe.mp4':\n",
    "    video = cap[935:1040]\n",
    "elif filename == 'video_SuperMario.mp4':\n",
    "    video = cap[1430:1650]\n",
    "elif filename == 'video_Kinjaz.mp4':\n",
    "    video = cap[2740:3170]\n",
    "elif filename == 'video_Kinjaz2.mp4':\n",
    "    video = cap[180:450]\n",
    "elif filename == 'video_PeopleDance.mp4':\n",
    "    video = cap[600:900]\n",
    "elif filename == 'video_Aaron.mp4':\n",
    "    video = cap[1520:1720]\n",
    "elif filename == 'video_Allen-lock.mp4':\n",
    "    video = cap[670:930]\n",
    "elif filename == 'video_funky-dance.mp4y-dance.mp4':\n",
    "    video = cap[3900:4150]\n",
    "else:\n",
    "    video = cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone_timing = [0, 60, 120, 180, len(video)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 128.188, output shape: (220, 288, 513, 3)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "oriv = list()\n",
    "newv = list()\n",
    "clone = np.zeros((288, 513, 3), dtype=np.uint8)\n",
    "for t in range(len(video)):\n",
    "    print('{}/{}'.format(t, len(video)), end='\\r')\n",
    "    \n",
    "    image, mask = run_visualization(video[t])\n",
    "    image = np.array(image)\n",
    "    fore  = np.array(mask == 15, np.uint8)\n",
    "    mask = np.stack((fore, fore, fore),axis=2)\n",
    "    \n",
    "    if t in clone_timing:\n",
    "        clone = mask*image\n",
    "        clone = clone.astype(np.uint8)\n",
    "    this_clone = clone * (1-(mask>0))    \n",
    "    \n",
    "    # find contours on person semantic mask\n",
    "    k = find_cntr((mask*255).astype(np.uint8))\n",
    "\n",
    "    # select at most five contours\n",
    "    num = min(len(k), 5)\n",
    "    colors = np.array([(252,141,98),(102,194,165), (141,160,203),(231,138,195),(166,216,84)]).astype(np.uint8)\n",
    "\n",
    "    # combine all contours with different colors\n",
    "    s = np.zeros(image.shape, np.uint8)\n",
    "    for i in range(num):\n",
    "        canvas = np.zeros(image.shape[0:2], np.uint8)\n",
    "        fore = cv2.drawContours(canvas, k, i, (255,255,255),-1)\n",
    "        s += cv2.medianBlur(get_stroke(fore, width=10)*colors[i], 1)\n",
    "\n",
    "    # combine with original images\n",
    "    image_new = image* (1-(this_clone>0)) + this_clone\n",
    "    image_new = image_new *(1-(s>0)) + s\n",
    "#     image_new = image_new * (1-(this_clone>0)) + this_clone\n",
    "    \n",
    "    oriv.append(image)\n",
    "    newv.append(image_new)\n",
    "    \n",
    "oriv = np.array(oriv).astype(np.uint8)\n",
    "newv = np.array(newv).astype(np.uint8)\n",
    "print('time: {0:.3f}, output shape: {1}'.format(time.time()-start_time, newv.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/ffmpeg -y -f rawvideo -pix_fmt rgb24 -s 513x288 -i - /Users/cmchang/magic-effect/clone-video_SuperMario.mp4\n"
     ]
    }
   ],
   "source": [
    "skvideo.io.vwrite(fname='clone-{}'.format(filename), videodata = newv, backend='ffmpeg', verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = np.concatenate((oriv, np.zeros(shape=(*oriv.shape[0:2], 10, 3), dtype=np.uint8), newv), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/ffmpeg -y -f rawvideo -pix_fmt rgb24 -s 1036x288 -i - /Users/cmchang/magic-effect/clone-compare-video_SuperMario.mp4\n"
     ]
    }
   ],
   "source": [
    "skvideo.io.vwrite(fname='clone-compare-{}'.format(filename), videodata = comp, backend='ffmpeg', verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('clone-{}.npy'.format(filename[:-4]), newv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
